{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d3527f",
   "metadata": {},
   "source": [
    "# PACS Domain Generalization with Vision Transformer (ViT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0ecd8",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a796be35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Updated import to include the base ViTModel\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ViTForImageClassification, ViTFeatureExtractor, ViTModel\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Updated import to include the base ViTModel\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor, ViTModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639f1eb",
   "metadata": {},
   "source": [
    "## Configuration and Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5145ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "SEED = 42\n",
    "BATCH_SIZE = 24\n",
    "NUM_EPOCHS = 5\n",
    "NUM_CLASSES = 7\n",
    "DATA_ROOT = \"../../../pacs_data/pacs_data\"\n",
    "DOMAINS = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]\n",
    "MODELS = {\n",
    "    \"base\": \"google/vit-base-patch16-224-in21k\",\n",
    "    \"small\": \"WinKawaks/vit-small-patch16-224\",\n",
    "    \"tiny\": \"WinKawaks/vit-tiny-patch16-224\"\n",
    "    }\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b48ac5",
   "metadata": {},
   "source": [
    "## Dataset Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9409c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PACSDataset:\n",
    "    def __init__(self, data_root, domains, transform):\n",
    "        self.data_root = data_root\n",
    "        self.domains = domains\n",
    "        self.transform = transform\n",
    "\n",
    "    def get_dataloader(self, domain, train=True):\n",
    "        dataset = datasets.ImageFolder(os.path.join(self.data_root, domain), transform=self.transform)\n",
    "        \n",
    "        indices = list(range(len(dataset)))\n",
    "        train_idx, val_idx = train_test_split(indices, test_size=0.2, stratify=[dataset.targets[i] for i in indices], random_state=SEED)\n",
    "        selected_idx = train_idx if train else val_idx\n",
    "        \n",
    "        subset = Subset(dataset, selected_idx)\n",
    "        loader = DataLoader(subset, batch_size=BATCH_SIZE, shuffle=train)\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9cc55",
   "metadata": {},
   "source": [
    "## Vision Transformer Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23595373",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTModel(nn.Module):\n",
    "    def __init__(self, num_classes, model_size=\"base\"):\n",
    "        super(ViTModel, self).__init__()\n",
    "        # Change 1: Load the base ViTModel, not the one for image classification\n",
    "        self.model = ViTModel.from_pretrained(\n",
    "            MODELS[model_size]\n",
    "        )\n",
    "        \n",
    "        # Change 2: Define our custom \"thinking\" head\n",
    "        hidden_size = self.model.config.hidden_size # This is 768 for the base model\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Change 3: Update the forward pass logic\n",
    "        # Pass input through the base model\n",
    "        outputs = self.model(x)\n",
    "        # Get the feature vector for the [CLS] token\n",
    "        cls_token_features = outputs.last_hidden_state[:, 0, :]\n",
    "        # Pass the features through our custom head\n",
    "        logits = self.classifier_head(cls_token_features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d86814",
   "metadata": {},
   "source": [
    "## Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c203fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, criterion):\n",
    "        self.model = model.to(DEVICE)\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def train(self, dataloader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return total_loss / len(dataloader)\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Change 1: Manually set the dropout layers in our custom head to train mode\n",
    "        # This keeps them active during evaluation for Monte Carlo Dropout\n",
    "        for module in self.model.classifier_head.modules():\n",
    "            if isinstance(module, nn.Dropout):\n",
    "                module.train()\n",
    "\n",
    "        total_correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                \n",
    "                # Change 2: Perform N=20 forward passes to get an ensemble of predictions\n",
    "                ensemble_preds = []\n",
    "                for _ in range(20): # N=20 passes\n",
    "                    outputs = self.model(inputs)\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    ensemble_preds.append(preds.unsqueeze(0))\n",
    "                \n",
    "                # Change 3: Calculate the majority vote for the final prediction\n",
    "                stacked_preds = torch.cat(ensemble_preds, dim=0)\n",
    "                final_preds, _ = torch.mode(stacked_preds, dim=0)\n",
    "\n",
    "                total_correct += (final_preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        return total_correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348587af",
   "metadata": {},
   "source": [
    "# Stochastic Ensemble ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c03ea",
   "metadata": {},
   "source": [
    "## Leave-One-Domain-Out (LODO) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0eba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "results_base = {}\n",
    "\n",
    "for test_domain in DOMAINS:\n",
    "    print(f\"\\nTesting on domain: {test_domain}\")\n",
    "    train_domains = [d for d in DOMAINS if d != test_domain]\n",
    "\n",
    "    # Load datasets\n",
    "    dataset = PACSDataset(DATA_ROOT, DOMAINS, transform)\n",
    "    train_loaders = [dataset.get_dataloader(d, train=True) for d in train_domains]\n",
    "    val_loaders = [dataset.get_dataloader(d, train=False) for d in train_domains]\n",
    "    test_loader = dataset.get_dataloader(test_domain, train=False)\n",
    "\n",
    "    # Concatenate datasets\n",
    "    train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "    val_ds = ConcatDataset([dl.dataset for dl in val_loaders])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Initialize model, optimizer, and criterion\n",
    "    model_base = ViTModel(NUM_CLASSES, model_size=\"base\")\n",
    "    optimizer = optim.Adam(model_base.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trainer = Trainer(model_base, optimizer, criterion)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "        train_loss_base = trainer.train(train_loader)\n",
    "        val_acc_base = trainer.evaluate(val_loader)\n",
    "        print(f\"Train Loss: {train_loss_base:.4f} | Val Acc: {val_acc_base:.4f}\")\n",
    "\n",
    "    # Test\n",
    "    test_acc_base = trainer.evaluate(test_loader)\n",
    "    results_base[test_domain] = test_acc_base\n",
    "    print(f\"Test Accuracy on {test_domain}: {test_acc_base:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
