{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e98ad332",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1555c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "except NameError:\n",
    "    # Fallback for Jupyter/interactive mode\n",
    "    project_root = os.path.abspath(\"..\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Standard library imports\n",
    "import random\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local imports\n",
    "from src.models.vit_wrapper import ViTModel\n",
    "from src.models.vgg import VGGWrapper\n",
    "from src.data.dataset_wrapper import PACSDataset\n",
    "from src.utils.trainer import Trainer\n",
    "from src.utils.configuration import (\n",
    "    DEVICE, SEED, BATCH_SIZE, NUM_EPOCHS,\n",
    "    NUM_CLASSES, DATA_ROOT, DOMAINS, MODELS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba72c34",
   "metadata": {},
   "source": [
    "# ViT Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1a6ce",
   "metadata": {},
   "source": [
    "## Leave-One-Domain-Out (LODO) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394d36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85442e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_base = {}\n",
    "\n",
    "for test_domain in DOMAINS:\n",
    "    print(f\"\\nTesting on domain: {test_domain}\")\n",
    "    train_domains = [d for d in DOMAINS if d != test_domain]\n",
    "\n",
    "    # Load datasets\n",
    "    dataset = PACSDataset(DATA_ROOT, DOMAINS, transform)\n",
    "    train_loaders = [dataset.get_dataloader(d, train=True) for d in train_domains]\n",
    "    val_loaders = [dataset.get_dataloader(d, train=False) for d in train_domains]\n",
    "    test_loader = dataset.get_dataloader(test_domain, train=False)\n",
    "\n",
    "    # Concatenate datasets\n",
    "    train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "    val_ds = ConcatDataset([dl.dataset for dl in val_loaders])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Initialize model, optimizer, and criterion\n",
    "    model_base = ViTModel(NUM_CLASSES, model_size=\"base\")\n",
    "    optimizer = optim.Adam(model_base.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trainer = Trainer(model_base, optimizer, criterion)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "        train_loss_base = trainer.train(train_loader)\n",
    "        val_acc_base = trainer.evaluate(val_loader)\n",
    "        print(f\"Train Loss: {train_loss_base:.4f} | Val Acc: {val_acc_base:.4f}\")\n",
    "\n",
    "    # Test\n",
    "    test_acc_base = trainer.evaluate(test_loader)\n",
    "    results_base[test_domain] = test_acc_base\n",
    "    print(f\"Test Accuracy on {test_domain}: {test_acc_base:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ViT: Testing on domain: art_painting =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7e6c022ff747bf808cde69963ce1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f25037e68743c58b55ca478decf598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ViT] Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [01:05<00:00,  4.04it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ViT] Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain(train_loader)\n\u001b[0;32m---> 26\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ViT] Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(test_loader)\n",
      "File \u001b[0;32m/mnt/truenas_smb/pacs/Visual-Reasoning/ModifiedGRPO/src/utils/trainer.py:52\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     49\u001b[0m         stacked_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(ensemble_preds, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     50\u001b[0m         final_preds, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmode(stacked_preds, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m         total_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mfinal_preds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_correct \u001b[38;5;241m/\u001b[39m total\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_vgg = {}\n",
    "DATA_ROOT = \"/mnt/truenas_smb/pacs_data/pacs_data\"\n",
    "\n",
    "# ---------------- LODO (Leave-One-Domain-Out) ----------------\n",
    "for test_domain in DOMAINS:\n",
    "    print(f\"\\n===== VGG11 LODO: Testing on domain: {test_domain} =====\")\n",
    "    train_domains = [d for d in DOMAINS if d != test_domain]\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = PACSDataset(DATA_ROOT, DOMAINS, transform)\n",
    "    train_loaders = [dataset.get_dataloader(d, train=True) for d in train_domains]\n",
    "    val_loaders = [dataset.get_dataloader(d, train=False) for d in train_domains]\n",
    "    test_loader = dataset.get_dataloader(test_domain, train=False)\n",
    "\n",
    "    # Concatenate datasets\n",
    "    train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "    val_ds = ConcatDataset([dl.dataset for dl in val_loaders])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Initialize model, optimizer, loss\n",
    "    model_vgg = VGGWrapper(NUM_CLASSES, pretrained=True)\n",
    "    optimizer = optim.Adam(model_vgg.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trainer = Trainer(model_vgg, optimizer, criterion)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"[VGG11-LODO] Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "        train_loss = trainer.train(train_loader)\n",
    "        val_acc = trainer.evaluate(val_loader)\n",
    "        print(f\"[VGG11-LODO] Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Test on the left-out domain\n",
    "    test_acc = trainer.evaluate(test_loader)\n",
    "    results_vgg[test_domain] = test_acc\n",
    "    print(f\"[VGG11-LODO] Test Accuracy on {test_domain}: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "# ---------------- Baseline: Train on ALL domains ----------------\n",
    "print(\"\\n===== VGG11 Baseline: Training on ALL domains =====\")\n",
    "\n",
    "# Load dataset with all domains\n",
    "dataset = PACSDataset(DATA_ROOT, DOMAINS, transform)\n",
    "train_loaders = [dataset.get_dataloader(d, train=True) for d in DOMAINS]\n",
    "val_loaders = [dataset.get_dataloader(d, train=False) for d in DOMAINS]\n",
    "\n",
    "train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "val_ds = ConcatDataset([dl.dataset for dl in val_loaders])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Model\n",
    "baseline_model = VGGWrapper(NUM_CLASSES, pretrained=True)\n",
    "optimizer = optim.Adam(baseline_model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trainer = Trainer(baseline_model, optimizer, criterion)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"[VGG11-Baseline] Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    train_loss = trainer.train(train_loader)\n",
    "    val_acc = trainer.evaluate(val_loader)\n",
    "    print(f\"[VGG11-Baseline] Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Final eval on all domains combined\n",
    "baseline_acc = trainer.evaluate(val_loader)\n",
    "print(f\"[VGG11-Baseline] Final Accuracy (all domains): {baseline_acc:.4f}\")\n",
    "\n",
    "\n",
    "# ---------------- Final Results ----------------\n",
    "print(\"\\n===== Final Results =====\")\n",
    "print(\"VGG11 LODO Accuracies:\", results_vgg)\n",
    "print(\"VGG11 Baseline Accuracy (all domains):\", baseline_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0612afcd",
   "metadata": {},
   "source": [
    "## Basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48651ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\Baseline: training on all domains and testing on mixed domains\")\n",
    "# Load full train and test sets via leave-all-in loaders\n",
    "dataset_all = PACSDataset(DATA_ROOT, DOMAINS, transform)\n",
    "all_train_loaders = [dataset_all.get_dataloader(d, train=True) for d in DOMAINS]\n",
    "all_test_loaders = [dataset_all.get_dataloader(d, train=False) for d in DOMAINS]\n",
    "\n",
    "# Concatenate\n",
    "full_train_ds = ConcatDataset([dl.dataset for dl in all_train_loaders])\n",
    "full_test_ds = ConcatDataset([dl.dataset for dl in all_test_loaders])\n",
    "full_train_loader = DataLoader(full_train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "full_test_loader = DataLoader(full_test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize baseline model\n",
    "baseline_model_base = ViTModel(NUM_CLASSES, model_size=\"base\")\n",
    "baseline_optimizer = optim.Adam(baseline_model_base.parameters(), lr=1e-4)\n",
    "baseline_criterion = nn.CrossEntropyLoss()\n",
    "baseline_trainer = Trainer(baseline_model_base, baseline_optimizer, baseline_criterion)\n",
    "\n",
    "# Train baseline\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Baseline Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    baseline_loss_base = baseline_trainer.train(full_train_loader)\n",
    "    baseline_val_acc_base = baseline_trainer.evaluate(full_test_loader)\n",
    "    print(f\"Baseline Loss: {baseline_loss_base:.4f} | Baseline Acc: {baseline_val_acc_base:.4f}\")\n",
    "\n",
    "# Test baseline\n",
    "baseline_test_acc_base = baseline_trainer.evaluate(full_test_loader)\n",
    "results_base['baseline_all_domains'] = baseline_test_acc_base\n",
    "print(f\"Baseline Test Accuracy: {baseline_test_acc_base:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12df3e",
   "metadata": {},
   "source": [
    "## Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = list(results_base.keys())\n",
    "accuracies = [results_base[d] for d in domains]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(domains, accuracies)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Leave-One-Domain-Out vs. Baseline Accuracy (ViT Base)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba2182",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1aae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\Final Results (LODO Accuracy):\")\n",
    "for domain, acc in results_base.items():\n",
    "    print(f\"{domain}: {acc:.4f}\")\n",
    "\n",
    "avg_acc = sum(results_base.values()) / len(results_base)\n",
    "print(f\"\\nAverage Accuracy: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7092a3b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de4d66",
   "metadata": {},
   "source": [
    "# WinKawaks/ViT Small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa80e3",
   "metadata": {},
   "source": [
    "## Leave-One-Domain-Out (LODO) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "results_small = {}\n",
    "\n",
    "for test_domain in DOMAINS:\n",
    "    print(f\"\\Testing on domain: {test_domain}\")\n",
    "    train_domains = [d for d in DOMAINS if d != test_domain]\n",
    "\n",
    "    # Load datasets\n",
    "    dataset = PACSDataset(DATA_ROOT, DOMAINS, transform)\n",
    "    train_loaders = [dataset.get_dataloader(d, train=True) for d in train_domains]\n",
    "    val_loaders = [dataset.get_dataloader(d, train=False) for d in train_domains]\n",
    "    test_loader = dataset.get_dataloader(test_domain, train=False)\n",
    "\n",
    "    # Concatenate datasets\n",
    "    train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "    val_ds = ConcatDataset([dl.dataset for dl in val_loaders])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Initialize model, optimizer, and criterion\n",
    "    model_small = ViTModel(NUM_CLASSES, model_size=\"small\")\n",
    "    optimizer = optim.Adam(model_small.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trainer = Trainer(model_small, optimizer, criterion)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "        train_loss_small = trainer.train(train_loader)\n",
    "        val_acc_small = trainer.evaluate(val_loader)\n",
    "        print(f\"Train Loss: {train_loss_small:.4f} | Val Acc: {val_acc_small:.4f}\")\n",
    "\n",
    "    # Test\n",
    "    test_acc_small = trainer.evaluate(test_loader)\n",
    "    results_small[test_domain] = test_acc_small\n",
    "    print(f\"Test Accuracy on {test_domain}: {test_acc_small:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae73f4",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70364c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBaseline: training on all domains and testing on mixed domains\")\n",
    "# Load full train and test sets via leave-all-in loaders\n",
    "dataset_all = PACSDataset(DATA_ROOT, DOMAINS, transform)\n",
    "all_train_loaders = [dataset_all.get_dataloader(d, train=True) for d in DOMAINS]\n",
    "all_test_loaders = [dataset_all.get_dataloader(d, train=False) for d in DOMAINS]\n",
    "\n",
    "# Concatenate\n",
    "full_train_ds = ConcatDataset([dl.dataset for dl in all_train_loaders])\n",
    "full_test_ds = ConcatDataset([dl.dataset for dl in all_test_loaders])\n",
    "full_train_loader = DataLoader(full_train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "full_test_loader = DataLoader(full_test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize baseline model\n",
    "# CORRECTED: Added model_size=\"small\" to ensure the correct model is loaded.\n",
    "baseline_model_small = ViTModel(NUM_CLASSES, model_size=\"small\")\n",
    "baseline_optimizer = optim.Adam(baseline_model_small.parameters(), lr=1e-4)\n",
    "baseline_criterion = nn.CrossEntropyLoss()\n",
    "baseline_trainer = Trainer(baseline_model_small, baseline_optimizer, baseline_criterion)\n",
    "\n",
    "# Train baseline\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Baseline Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    baseline_loss_small = baseline_trainer.train(full_train_loader)\n",
    "    baseline_val_acc_small = baseline_trainer.evaluate(full_test_loader)\n",
    "    print(f\"Baseline Loss: {baseline_loss_small:.4f} | Baseline Acc: {baseline_val_acc_small:.4f}\")\n",
    "\n",
    "# Test baseline\n",
    "baseline_test_acc_small = baseline_trainer.evaluate(full_test_loader)\n",
    "results_small['baseline_all_domains'] = baseline_test_acc_small\n",
    "print(f\"Baseline Test Accuracy: {baseline_test_acc_small:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd349e91",
   "metadata": {},
   "source": [
    "## Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de92e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = list(results_small.keys())\n",
    "accuracies = [results_small[d] for d in domains]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(domains, accuracies)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Leave-One-Domain-Out vs. Baseline Accuracy (ViT Small)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e82a7",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2929cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\Final Results (LODO Accuracy):\")\n",
    "for domain, acc in results_small.items():\n",
    "    print(f\"{domain}: {acc:.4f}\")\n",
    "\n",
    "avg_acc = sum(results_small.values()) / len(results_small)\n",
    "print(f\"\\nAverage Accuracy: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ddc120",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b34d5",
   "metadata": {},
   "source": [
    "# WinKawaks/ViT Tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cbec4d",
   "metadata": {},
   "source": [
    "## Leave-One-Domain-Out (LODO) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83dcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WinKawaks/ViT Tiny\n",
    "# Leave-One-Domain-Out (LODO) Training\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "results_tiny = {}\n",
    "\n",
    "for test_domain in DOMAINS:\n",
    "    print(f\"\\nTesting on domain: {test_domain}\")\n",
    "    train_domains = [d for d in DOMAINS if d != test_domain]\n",
    "\n",
    "    # Load datasets\n",
    "    dataset = PACSDataset(DATA_ROOT, DOMAINS, transform)\n",
    "    train_loaders = [dataset.get_dataloader(d, train=True) for d in train_domains]\n",
    "    val_loaders = [dataset.get_dataloader(d, train=False) for d in train_domains]\n",
    "    test_loader = dataset.get_dataloader(test_domain, train=False)\n",
    "\n",
    "    # Concatenate datasets\n",
    "    train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "    val_ds = ConcatDataset([dl.dataset for dl in val_loaders])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Initialize model, optimizer, and criterion\n",
    "    model_tiny = ViTModel(NUM_CLASSES, model_size=\"tiny\")\n",
    "    # CORRECTED: Optimizer now uses parameters from model_tiny, not model_base.\n",
    "    optimizer = optim.Adam(model_tiny.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trainer = Trainer(model_tiny, optimizer, criterion)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "        train_loss_tiny = trainer.train(train_loader)\n",
    "        val_acc_tiny = trainer.evaluate(val_loader)\n",
    "        print(f\"Train Loss: {train_loss_tiny:.4f} | Val Acc: {val_acc_tiny:.4f}\")\n",
    "\n",
    "    # Test\n",
    "    test_acc_tiny = trainer.evaluate(test_loader)\n",
    "    results_tiny[test_domain] = test_acc_tiny\n",
    "    print(f\"Test Accuracy on {test_domain}: {test_acc_tiny:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0cd5a",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1af77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBaseline: training on all domains and testing on mixed domains\")\n",
    "# Load full train and test sets via leave-all-in loaders\n",
    "dataset_all = PACSDataset(DATA_ROOT, DOMAINS, transform)\n",
    "all_train_loaders = [dataset_all.get_dataloader(d, train=True) for d in DOMAINS]\n",
    "all_test_loaders = [dataset_all.get_dataloader(d, train=False) for d in DOMAINS]\n",
    "\n",
    "# Concatenate\n",
    "full_train_ds = ConcatDataset([dl.dataset for dl in all_train_loaders])\n",
    "full_test_ds = ConcatDataset([dl.dataset for dl in all_test_loaders])\n",
    "full_train_loader = DataLoader(full_train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "full_test_loader = DataLoader(full_test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize baseline model\n",
    "# CORRECTED: Added model_size=\"tiny\" to ensure the correct model is loaded.\n",
    "baseline_model_tiny = ViTModel(NUM_CLASSES, model_size=\"tiny\")\n",
    "baseline_optimizer = optim.Adam(baseline_model_tiny.parameters(), lr=1e-4)\n",
    "baseline_criterion = nn.CrossEntropyLoss()\n",
    "baseline_trainer = Trainer(baseline_model_tiny, baseline_optimizer, baseline_criterion)\n",
    "\n",
    "# Train baseline\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Baseline Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    baseline_loss_tiny = baseline_trainer.train(full_train_loader)\n",
    "    baseline_val_acc_tiny = baseline_trainer.evaluate(full_test_loader)\n",
    "    print(f\"Baseline Loss: {baseline_loss_tiny:.4f} | Baseline Acc: {baseline_val_acc_tiny:.4f}\")\n",
    "\n",
    "# Test baseline\n",
    "baseline_test_acc_tiny = baseline_trainer.evaluate(full_test_loader)\n",
    "results_tiny['baseline_all_domains'] = baseline_test_acc_tiny\n",
    "print(f\"Baseline Test Accuracy: {baseline_test_acc_tiny:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e70cf",
   "metadata": {},
   "source": [
    "## Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f07467",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = list(results_tiny.keys())\n",
    "accuracies = [results_tiny[d] for d in domains]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(domains, accuracies)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Leave-One-Domain-Out vs. Baseline Accuracy (ViT Tiny)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2ff05",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\Final Results (LODO Accuracy):\")\n",
    "for domain, acc in results_tiny.items():\n",
    "    print(f\"{domain}: {acc:.4f}\")\n",
    "\n",
    "avg_acc = sum(results_tiny.values()) / len(results_tiny)\n",
    "print(f\"\\nAverage Accuracy: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4111a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac25333",
   "metadata": {},
   "source": [
    "# Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5cc001",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx, domain in enumerate(DOMAINS):\n",
    "    plt.subplot(2, 3, idx + 1)\n",
    "\n",
    "    domain_accuracies = [\n",
    "        results_base[domain],\n",
    "        results_small[domain],\n",
    "        results_tiny[domain]\n",
    "    ]\n",
    "\n",
    "    bars = plt.bar(MODELS.keys(), domain_accuracies, color=[\"skyblue\", \"orange\", \"green\"])\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.title(f\"Model Comparison - {domain} Domain\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for i, acc in enumerate(domain_accuracies):\n",
    "        plt.text(i, acc + 0.01, f\"{acc:.2%}\", ha=\"center\")\n",
    "\n",
    "# Create the baseline comparison subplot\n",
    "plt.subplot(2, 3, 5) \n",
    "baseline_accuracies = [\n",
    "    results_base[\"baseline_all_domains\"],\n",
    "    results_small[\"baseline_all_domains\"],\n",
    "    results_tiny[\"baseline_all_domains\"]\n",
    "]\n",
    "plt.bar(MODELS.keys(), baseline_accuracies, color=[\"skyblue\", \"orange\", \"green\"])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Model Comparison - Baseline (All Domains)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "for i, acc in enumerate(baseline_accuracies):\n",
    "    plt.text(i, acc + 0.01, f\"{acc:.2%}\", ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDetailed Performance Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Domain':<15} {'Base':>10} {'Small':>10} {'Tiny':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for domain in DOMAINS:\n",
    "    print(f\"{domain:<15} {results_base[domain]:>10.2%} {results_small[domain]:>10.2%} {results_tiny[domain]:>10.2%}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Baseline':<15} {results_base['baseline_all_domains']:>10.2%} {results_small['baseline_all_domains']:>10.2%} {results_tiny['baseline_all_domains']:>10.2%}\")\n",
    "print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
