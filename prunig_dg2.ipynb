{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19183583",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"D:\\Haseeb\\Datasets\\pacs_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625299c3",
   "metadata": {},
   "source": [
    "### Layer_wise_L1norm_by_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b9ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "import os\n",
    "from dataset import get_pacs_dataloaders\n",
    "from utils import *\n",
    "from Layer_wise_pruning import iterative_pruning\n",
    "\n",
    "ALL_DOMAINS = ['art_painting', 'cartoon', 'photo', 'sketch']\n",
    "TARGET_DOMAIN = 'sketch'\n",
    "SOURCE_DOMAINS = [d for d in ALL_DOMAINS if d != TARGET_DOMAIN]\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"--- Starting Warmup Phase ---\")\n",
    "source_loader_combined, target_loader, class_to_idx = get_pacs_dataloaders(\n",
    "    data_dir=DATA_DIR, source_domains=SOURCE_DOMAINS, target_domain=TARGET_DOMAIN,\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, combine_sources=True\n",
    ")\n",
    "num_classes = len(class_to_idx)\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "WARMUP_EPOCHS = 5\n",
    "best_warmup_acc = 0.0\n",
    "WARMUP_MODEL_PATH = \"best_warmup_model.pth\"\n",
    "\n",
    "if os.path.exists(WARMUP_MODEL_PATH):\n",
    "    print(\"Warmup model already exists. Loading and skipping warmup...\")\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(WARMUP_MODEL_PATH, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "else:\n",
    "    print(\"No warmup model found. Running warmup training...\")\n",
    "    source_loader_combined, target_loader, class_to_idx = get_pacs_dataloaders(\n",
    "        data_dir=DATA_DIR, source_domains=SOURCE_DOMAINS, target_domain=TARGET_DOMAIN,\n",
    "        batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, combine_sources=True\n",
    "    )\n",
    "\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    WARMUP_EPOCHS = 5\n",
    "\n",
    "    for epoch in range(WARMUP_EPOCHS):\n",
    "        train_vanilla(model, source_loader_combined, optimizer, DEVICE, epoch)\n",
    "        _, val_acc = evaluate(model, target_loader, DEVICE)\n",
    "        print(f\"  Warmup Epoch {epoch+1} Target Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "        if val_acc > best_warmup_acc:\n",
    "            best_warmup_acc = val_acc\n",
    "            torch.save(model.state_dict(), WARMUP_MODEL_PATH)\n",
    "            print(f\"  New best warmup accuracy: {best_warmup_acc:.2f}%. Checkpoint saved.\")\n",
    "\n",
    "    print(f\"\\nWarmup finished. Best accuracy: {best_warmup_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n--- Starting Iterative Pruning Phase ---\")\n",
    "source_loaders_list, target_loader, _ = get_pacs_dataloaders(\n",
    "    data_dir=DATA_DIR, source_domains=SOURCE_DOMAINS, target_domain=TARGET_DOMAIN,\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, combine_sources=False\n",
    ")\n",
    "\n",
    "pruning_model = models.resnet18()\n",
    "pruning_model.fc = nn.Linear(pruning_model.fc.in_features, num_classes)\n",
    "pruning_model.load_state_dict(torch.load(WARMUP_MODEL_PATH))\n",
    "pruning_model.to(DEVICE)\n",
    "\n",
    "PRUNE_RATES = [0.10, 0.10, 0.10]\n",
    "FINETUNE_EPOCHS = 5\n",
    "FINETUNE_LR = 1e-4\n",
    "ALPHA = 1.0\n",
    "\n",
    "final_model, final_mask = iterative_pruning(\n",
    "    model=pruning_model,\n",
    "    source_loaders_list=source_loaders_list,\n",
    "    target_loader=target_loader,\n",
    "    device=DEVICE,\n",
    "    prune_rates=PRUNE_RATES,\n",
    "    retrain_epochs=FINETUNE_EPOCHS,\n",
    "    lr=FINETUNE_LR,\n",
    "    alpha=ALPHA,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    SFT=False,\n",
    "    importance_type=\"by_source\")\n",
    "\n",
    "# --- 4. Final Evaluation ---\n",
    "print(\"\\n--- Final Evaluation ---\")\n",
    "baseline_acc = best_warmup_acc\n",
    "apply_mask(final_model, final_mask)\n",
    "_, final_acc = evaluate(final_model, target_loader, DEVICE, mask=final_mask)\n",
    "\n",
    "print(\"\\n--- Pruning Summary ---\")\n",
    "print(f\"Baseline Target Accuracy (from best warmup): {baseline_acc:.2f}%\")\n",
    "print(f\"Final Target Accuracy (from best pruned model): {final_acc:.2f}%\")\n",
    "improvement = final_acc - baseline_acc\n",
    "print(f\"Improvement: {improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2974778",
   "metadata": {},
   "source": [
    "### Layer_wise_L1norm_by_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "import os\n",
    "from dataset import get_pacs_dataloaders\n",
    "from utils import *\n",
    "from Layer_wise_pruning import iterative_pruning\n",
    "\n",
    "ALL_DOMAINS = ['art_painting', 'cartoon', 'photo', 'sketch']\n",
    "TARGET_DOMAIN = 'sketch'\n",
    "SOURCE_DOMAINS = [d for d in ALL_DOMAINS if d != TARGET_DOMAIN]\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"--- Starting Warmup Phase ---\")\n",
    "source_loader_combined, target_loader, class_to_idx = get_pacs_dataloaders(\n",
    "    data_dir=DATA_DIR, source_domains=SOURCE_DOMAINS, target_domain=TARGET_DOMAIN,\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, combine_sources=True\n",
    ")\n",
    "num_classes = len(class_to_idx)\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "WARMUP_EPOCHS = 5\n",
    "best_warmup_acc = 0.0\n",
    "WARMUP_MODEL_PATH = \"best_warmup_model.pth\"\n",
    "\n",
    "if os.path.exists(WARMUP_MODEL_PATH):\n",
    "    print(\"Warmup model already exists. Loading and skipping warmup...\")\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(WARMUP_MODEL_PATH, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "else:\n",
    "    print(\"No warmup model found. Running warmup training...\")\n",
    "    source_loader_combined, target_loader, class_to_idx = get_pacs_dataloaders(\n",
    "        data_dir=DATA_DIR, source_domains=SOURCE_DOMAINS, target_domain=TARGET_DOMAIN,\n",
    "        batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, combine_sources=True\n",
    "    )\n",
    "\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    WARMUP_EPOCHS = 5\n",
    "\n",
    "    for epoch in range(WARMUP_EPOCHS):\n",
    "        train_vanilla(model, source_loader_combined, optimizer, DEVICE, epoch)\n",
    "        _, val_acc = evaluate(model, target_loader, DEVICE)\n",
    "        print(f\"  Warmup Epoch {epoch+1} Target Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "        if val_acc > best_warmup_acc:\n",
    "            best_warmup_acc = val_acc\n",
    "            torch.save(model.state_dict(), WARMUP_MODEL_PATH)\n",
    "            print(f\"  New best warmup accuracy: {best_warmup_acc:.2f}%. Checkpoint saved.\")\n",
    "\n",
    "    print(f\"\\nWarmup finished. Best accuracy: {best_warmup_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n--- Starting Iterative Pruning Phase ---\")\n",
    "source_loaders_list, target_loader, _ = get_pacs_dataloaders(\n",
    "    data_dir=DATA_DIR, source_domains=SOURCE_DOMAINS, target_domain=TARGET_DOMAIN,\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, combine_sources=False\n",
    ")\n",
    "\n",
    "pruning_model = models.resnet18()\n",
    "pruning_model.fc = nn.Linear(pruning_model.fc.in_features, num_classes)\n",
    "pruning_model.load_state_dict(torch.load(WARMUP_MODEL_PATH))\n",
    "pruning_model.to(DEVICE)\n",
    "\n",
    "PRUNE_RATES = [0.10, 0.10, 0.10]\n",
    "FINETUNE_EPOCHS = 5\n",
    "FINETUNE_LR = 1e-4\n",
    "ALPHA = 1.0\n",
    "\n",
    "final_model, final_mask = iterative_pruning(\n",
    "    model=pruning_model,\n",
    "    source_loaders_list=source_loaders_list,\n",
    "    target_loader=target_loader,\n",
    "    device=DEVICE,\n",
    "    prune_rates=PRUNE_RATES,\n",
    "    retrain_epochs=FINETUNE_EPOCHS,\n",
    "    lr=FINETUNE_LR,\n",
    "    alpha=ALPHA,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    SFT=False,\n",
    "    importance_type=\"by_target\")\n",
    "\n",
    "# --- 4. Final Evaluation ---\n",
    "print(\"\\n--- Final Evaluation ---\")\n",
    "baseline_acc = best_warmup_acc\n",
    "apply_mask(final_model, final_mask)\n",
    "_, final_acc = evaluate(final_model, target_loader, DEVICE, mask=final_mask)\n",
    "\n",
    "print(\"\\n--- Pruning Summary ---\")\n",
    "print(f\"Baseline Target Accuracy (from best warmup): {baseline_acc:.2f}%\")\n",
    "print(f\"Final Target Accuracy (from best pruned model): {final_acc:.2f}%\")\n",
    "improvement = final_acc - baseline_acc\n",
    "print(f\"Improvement: {improvement:+.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
