{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b54d51",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ed7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haseeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "from model import LatenViTtiny\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from PIL import Image\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8966fc6",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdcfdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config:\n",
    "    MODEL_NAME   = 'tiny_vit_21m_224.dist_in22k_ft_in1k'\n",
    "    NUM_CLASSES  = 7      \n",
    "    NREPEAT      = 2\n",
    "    stage = 2\n",
    "    \n",
    "    BATCH_SIZE   = 128\n",
    "    NUM_EPOCHS   = 5\n",
    "    LEARNING_RATE= 1e-4\n",
    "    DEVICE       = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    DATA_ROOT    = \"../../../pacs_data/pacs_data\"\n",
    "    DOMAINS      = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]\n",
    "    \n",
    "    TRANSFORM = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07547270",
   "metadata": {},
   "source": [
    "### PACS Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d5a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PACSDataset(Dataset):\n",
    "    def __init__(self, root_dir, domain, transform=None):\n",
    "        self.root_dir    = os.path.join(root_dir, domain)\n",
    "        self.transform   = transform\n",
    "        self.classes     = sorted(os.listdir(self.root_dir))\n",
    "        self.class_to_idx= {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.images      = []\n",
    "        self.labels      = []\n",
    "        \n",
    "        for cls_name in self.classes:\n",
    "            cls_dir = os.path.join(self.root_dir, cls_name)\n",
    "            for img_name in os.listdir(cls_dir):\n",
    "                self.images.append(os.path.join(cls_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[cls_name])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image    = Image.open(img_path).convert('RGB')\n",
    "        label    = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95fe33e",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1af0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "    base_model = timm.create_model(Config.MODEL_NAME, pretrained=True)\n",
    "    model = LatenViTtiny(\n",
    "        model     = base_model,\n",
    "        nrepeat   = Config.NREPEAT,\n",
    "        stage = Config.stage\n",
    "    )\n",
    "    return model.to(Config.DEVICE)\n",
    "\n",
    "def setup_baseline_model():\n",
    "    base_model = timm.create_model(Config.MODEL_NAME, pretrained=True)\n",
    "    return base_model.to(Config.DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db40587",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489747cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct      = 0\n",
    "    total        = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted  = outputs.max(1)\n",
    "        total        += labels.size(0)\n",
    "        correct      += predicted.eq(labels).sum().item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc  = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d5b1e",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ee5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "        outputs        = model(images)\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        total       += labels.size(0)\n",
    "        correct     += predicted.eq(labels).sum().item()\n",
    "        \n",
    "    return 100.0 * correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec7a5ba",
   "metadata": {},
   "source": [
    "### Baseline -CotFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d57310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] Train Loss: 3.7127, Train Acc: 12.86%\n",
      "[Epoch 2/5] Train Loss: 2.5703, Train Acc: 17.26%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loaders = []\n",
    "test_loaders  = []\n",
    "for domain in Config.DOMAINS:\n",
    "    ds_train = PACSDataset(Config.DATA_ROOT, domain, Config.TRANSFORM)\n",
    "    ds_test  = PACSDataset(Config.DATA_ROOT, domain, Config.TRANSFORM)\n",
    "    train_loaders.append(DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True))\n",
    "    test_loaders .append(DataLoader(ds_test,  batch_size=Config.BATCH_SIZE, shuffle=False))\n",
    "\n",
    "\n",
    "full_train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "full_test_ds  = ConcatDataset([dl.dataset  for dl in test_loaders ])\n",
    "full_train_loader = DataLoader(full_train_ds, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "full_test_loader  = DataLoader(full_test_ds,  batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model     = setup_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, Config.NUM_EPOCHS + 1):\n",
    "    loss, acc = train_epoch(model, full_train_loader, criterion, optimizer)\n",
    "    print(f\"[Epoch {epoch}/{Config.NUM_EPOCHS}] Train Loss: {loss:.4f}, Train Acc: {acc:.2f}%\")\n",
    "\n",
    "test_acc = evaluate(model, full_test_loader)\n",
    "print(f\"Baseline (all domains) Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n[Per-Domain Evaluation]\")\n",
    "domain_accuracies = OrderedDict()\n",
    "for domain, loader in zip(Config.DOMAINS, test_loaders):\n",
    "    acc = evaluate(model, loader)\n",
    "    domain_accuracies[domain] = acc\n",
    "    print(f\"  {domain:>12}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = Config.TRANSFORM  \n",
    "\n",
    "lodo_results = OrderedDict()\n",
    "\n",
    "for test_domain in Config.DOMAINS:\n",
    "    print(f\"\\n=== LODO: Held-Out Domain = {test_domain} ===\")\n",
    "    train_loaders = []\n",
    "    for d in Config.DOMAINS:\n",
    "        if d == test_domain:\n",
    "            continue\n",
    "        ds_train = PACSDataset(Config.DATA_ROOT, d, transform)\n",
    "        train_loaders.append(DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True))\n",
    "\n",
    "    train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "    train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    ds_test    = PACSDataset(Config.DATA_ROOT, test_domain, transform)\n",
    "    test_loader = DataLoader(ds_test, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model     = setup_model()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(1, Config.NUM_EPOCHS + 1):\n",
    "        loss, acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        print(f\"[Epoch {epoch}/{Config.NUM_EPOCHS}] Train Loss: {loss:.4f}, Train Acc: {acc:.2f}%\")\n",
    "\n",
    "    test_acc = evaluate(model, test_loader)\n",
    "    lodo_results[test_domain] = test_acc\n",
    "    print(f\"--> Test Accuracy on {test_domain}: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n=== LODO Summary ===\")\n",
    "for domain, acc in lodo_results.items():\n",
    "    print(f\"{domain:>14}: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3284a591",
   "metadata": {},
   "source": [
    "### Baseline Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648a4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] Train Loss: 3.0058, Train Acc: 46.13%\n",
      "[Epoch 2/5] Train Loss: 0.5827, Train Acc: 87.52%\n",
      "[Epoch 3/5] Train Loss: 0.2492, Train Acc: 93.63%\n",
      "[Epoch 4/5] Train Loss: 0.1634, Train Acc: 95.99%\n",
      "[Epoch 5/5] Train Loss: 0.1144, Train Acc: 96.85%\n",
      "Baseline (all domains) Test Accuracy: 99.46%\n",
      "\n",
      "[Per-Domain Evaluation]\n",
      "  art_painting: 99.90%\n",
      "       cartoon: 99.49%\n",
      "         photo: 99.94%\n",
      "        sketch: 99.01%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loaders = []\n",
    "test_loaders  = []\n",
    "for domain in Config.DOMAINS:\n",
    "    ds_train = PACSDataset(Config.DATA_ROOT, domain, Config.TRANSFORM)\n",
    "    ds_test  = PACSDataset(Config.DATA_ROOT, domain, Config.TRANSFORM)\n",
    "    train_loaders.append(DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True))\n",
    "    test_loaders .append(DataLoader(ds_test,  batch_size=Config.BATCH_SIZE, shuffle=False))\n",
    "\n",
    "\n",
    "full_train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "full_test_ds  = ConcatDataset([dl.dataset  for dl in test_loaders ])\n",
    "full_train_loader = DataLoader(full_train_ds, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "full_test_loader  = DataLoader(full_test_ds,  batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model     = setup_baseline_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, Config.NUM_EPOCHS + 1):\n",
    "    loss, acc = train_epoch(model, full_train_loader, criterion, optimizer)\n",
    "    print(f\"[Epoch {epoch}/{Config.NUM_EPOCHS}] Train Loss: {loss:.4f}, Train Acc: {acc:.2f}%\")\n",
    "\n",
    "test_acc = evaluate(model, full_test_loader)\n",
    "print(f\"Baseline (all domains) Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n[Per-Domain Evaluation]\")\n",
    "domain_accuracies = OrderedDict()\n",
    "for domain, loader in zip(Config.DOMAINS, test_loaders):\n",
    "    acc = evaluate(model, loader)\n",
    "    domain_accuracies[domain] = acc\n",
    "    print(f\"  {domain:>12}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47259f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LODO: Held-Out Domain = art_painting ===\n",
      "[Epoch 1/5] Train Loss: 3.2942, Train Acc: 41.70%\n",
      "[Epoch 2/5] Train Loss: 0.7274, Train Acc: 84.53%\n",
      "[Epoch 3/5] Train Loss: 0.3054, Train Acc: 92.60%\n",
      "[Epoch 4/5] Train Loss: 0.2077, Train Acc: 94.86%\n",
      "[Epoch 5/5] Train Loss: 0.1318, Train Acc: 96.44%\n",
      "--> Test Accuracy on art_painting: 85.50%\n",
      "\n",
      "=== LODO: Held-Out Domain = cartoon ===\n",
      "[Epoch 1/5] Train Loss: 3.4373, Train Acc: 40.77%\n",
      "[Epoch 2/5] Train Loss: 0.7122, Train Acc: 85.04%\n",
      "[Epoch 3/5] Train Loss: 0.2976, Train Acc: 92.73%\n",
      "[Epoch 4/5] Train Loss: 0.1706, Train Acc: 95.49%\n",
      "[Epoch 5/5] Train Loss: 0.1006, Train Acc: 97.08%\n",
      "--> Test Accuracy on cartoon: 78.50%\n",
      "\n",
      "=== LODO: Held-Out Domain = photo ===\n",
      "[Epoch 1/5] Train Loss: 3.4844, Train Acc: 38.53%\n",
      "[Epoch 2/5] Train Loss: 0.9777, Train Acc: 80.94%\n",
      "[Epoch 3/5] Train Loss: 0.4085, Train Acc: 90.43%\n",
      "[Epoch 4/5] Train Loss: 0.2471, Train Acc: 93.47%\n",
      "[Epoch 5/5] Train Loss: 0.2597, Train Acc: 95.42%\n",
      "--> Test Accuracy on photo: 97.66%\n",
      "\n",
      "=== LODO: Held-Out Domain = sketch ===\n",
      "[Epoch 1/5] Train Loss: 4.2164, Train Acc: 31.71%\n",
      "[Epoch 2/5] Train Loss: 0.7261, Train Acc: 86.11%\n",
      "[Epoch 3/5] Train Loss: 0.2853, Train Acc: 94.03%\n",
      "[Epoch 4/5] Train Loss: 0.1469, Train Acc: 96.80%\n",
      "[Epoch 5/5] Train Loss: 0.0916, Train Acc: 97.99%\n",
      "--> Test Accuracy on sketch: 80.05%\n",
      "\n",
      "=== LODO Summary ===\n",
      "  art_painting: 85.50%\n",
      "       cartoon: 78.50%\n",
      "         photo: 97.66%\n",
      "        sketch: 80.05%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = Config.TRANSFORM  \n",
    "\n",
    "lodo_results = OrderedDict()\n",
    "\n",
    "for test_domain in Config.DOMAINS:\n",
    "    print(f\"\\n=== LODO: Held-Out Domain = {test_domain} ===\")\n",
    "    train_loaders = []\n",
    "    for d in Config.DOMAINS:\n",
    "        if d == test_domain:\n",
    "            continue\n",
    "        ds_train = PACSDataset(Config.DATA_ROOT, d, transform)\n",
    "        train_loaders.append(DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True))\n",
    "\n",
    "    train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "    train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    ds_test    = PACSDataset(Config.DATA_ROOT, test_domain, transform)\n",
    "    test_loader = DataLoader(ds_test, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model     = setup_baseline_model()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(1, Config.NUM_EPOCHS + 1):\n",
    "        loss, acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        print(f\"[Epoch {epoch}/{Config.NUM_EPOCHS}] Train Loss: {loss:.4f}, Train Acc: {acc:.2f}%\")\n",
    "\n",
    "    test_acc = evaluate(model, test_loader)\n",
    "    lodo_results[test_domain] = test_acc\n",
    "    print(f\"--> Test Accuracy on {test_domain}: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n=== LODO Summary ===\")\n",
    "for domain, acc in lodo_results.items():\n",
    "    print(f\"{domain:>14}: {acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
