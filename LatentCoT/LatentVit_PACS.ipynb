{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b54d51",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ed7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haseeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "from model import LatenViTSmall\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8966fc6",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fdcfdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Config:\n",
    "    MODEL_NAME   = 'vit_small_patch16_224.augreg_in21k'\n",
    "    NUM_CLASSES  = 7      \n",
    "    NREPEAT      = 3\n",
    "    START_BLOCK  = 4\n",
    "    END_BLOCK    = 10\n",
    "    NUM_LAYERS   = 11\n",
    "    \n",
    "    BATCH_SIZE   = 64\n",
    "    NUM_EPOCHS   = 5\n",
    "    LEARNING_RATE= 1e-4\n",
    "    DEVICE       = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    DATA_ROOT    = \"../../../pacs_data/pacs_data\"\n",
    "    DOMAINS      = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]\n",
    "    \n",
    "    TRANSFORM = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07547270",
   "metadata": {},
   "source": [
    "### PACS Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d5a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PACSDataset(Dataset):\n",
    "    def __init__(self, root_dir, domain, transform=None):\n",
    "        self.root_dir    = os.path.join(root_dir, domain)\n",
    "        self.transform   = transform\n",
    "        self.classes     = sorted(os.listdir(self.root_dir))\n",
    "        self.class_to_idx= {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.images      = []\n",
    "        self.labels      = []\n",
    "        \n",
    "        for cls_name in self.classes:\n",
    "            cls_dir = os.path.join(self.root_dir, cls_name)\n",
    "            for img_name in os.listdir(cls_dir):\n",
    "                self.images.append(os.path.join(cls_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[cls_name])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image    = Image.open(img_path).convert('RGB')\n",
    "        label    = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95fe33e",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1af0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "    base_model = timm.create_model(Config.MODEL_NAME, pretrained=True)\n",
    "    model = LatenViTSmall(\n",
    "        model     = base_model,\n",
    "        nrepeat   = Config.NREPEAT,\n",
    "        start     = Config.START_BLOCK,\n",
    "        end       = Config.END_BLOCK,\n",
    "        num_layers= Config.NUM_LAYERS\n",
    "    )\n",
    "    return model.to(Config.DEVICE)\n",
    "\n",
    "def setup_baseline_model():\n",
    "    base_model = timm.create_model(Config.MODEL_NAME, pretrained=True)\n",
    "    base_model.head = nn.Linear(base_model.head.in_features, Config.NUM_CLASSES)\n",
    "    return base_model.to(Config.DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db40587",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489747cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct      = 0\n",
    "    total        = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted  = outputs.max(1)\n",
    "        total        += labels.size(0)\n",
    "        correct      += predicted.eq(labels).sum().item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc  = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d5b1e",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ee5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "        outputs        = model(images)\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        total       += labels.size(0)\n",
    "        correct     += predicted.eq(labels).sum().item()\n",
    "        \n",
    "    return 100.0 * correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec7a5ba",
   "metadata": {},
   "source": [
    "### Baseline -CotFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d57310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] Train Loss: 1.4687, Train Acc: 53.45%\n",
      "[Epoch 2/5] Train Loss: 0.6216, Train Acc: 76.32%\n",
      "[Epoch 3/5] Train Loss: 0.3985, Train Acc: 85.04%\n",
      "[Epoch 4/5] Train Loss: 0.2210, Train Acc: 91.95%\n",
      "[Epoch 5/5] Train Loss: 0.1485, Train Acc: 94.92%\n",
      "Baseline (all domains) Test Accuracy: 97.10%\n",
      "\n",
      "[Per-Domain Evaluation]\n",
      "  art_painting: 96.68%\n",
      "       cartoon: 98.76%\n",
      "         photo: 99.64%\n",
      "        sketch: 95.24%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loaders = []\n",
    "test_loaders  = []\n",
    "for domain in Config.DOMAINS:\n",
    "    ds_train = PACSDataset(Config.DATA_ROOT, domain, Config.TRANSFORM)\n",
    "    ds_test  = PACSDataset(Config.DATA_ROOT, domain, Config.TRANSFORM)\n",
    "    train_loaders.append(DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True))\n",
    "    test_loaders .append(DataLoader(ds_test,  batch_size=Config.BATCH_SIZE, shuffle=False))\n",
    "\n",
    "\n",
    "full_train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "full_test_ds  = ConcatDataset([dl.dataset  for dl in test_loaders ])\n",
    "full_train_loader = DataLoader(full_train_ds, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "full_test_loader  = DataLoader(full_test_ds,  batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model     = setup_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, Config.NUM_EPOCHS + 1):\n",
    "    loss, acc = train_epoch(model, full_train_loader, criterion, optimizer)\n",
    "    print(f\"[Epoch {epoch}/{Config.NUM_EPOCHS}] Train Loss: {loss:.4f}, Train Acc: {acc:.2f}%\")\n",
    "\n",
    "test_acc = evaluate(model, full_test_loader)\n",
    "print(f\"Baseline (all domains) Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "from collections import OrderedDict\n",
    "print(\"\\n[Per-Domain Evaluation]\")\n",
    "domain_accuracies = OrderedDict()\n",
    "for domain, loader in zip(Config.DOMAINS, test_loaders):\n",
    "    acc = evaluate(model, loader)\n",
    "    domain_accuracies[domain] = acc\n",
    "    print(f\"  {domain:>12}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3284a591",
   "metadata": {},
   "source": [
    "### Baseline Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648a4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5] Train Loss: 0.2591, Train Acc: 91.09%\n",
      "[Epoch 2/5] Train Loss: 0.0579, Train Acc: 98.12%\n",
      "[Epoch 3/5] Train Loss: 0.0398, Train Acc: 98.93%\n",
      "[Epoch 4/5] Train Loss: 0.0411, Train Acc: 98.73%\n",
      "[Epoch 5/5] Train Loss: 0.0213, Train Acc: 99.23%\n",
      "Baseline (all domains) Test Accuracy: 98.92%\n",
      "\n",
      "[Per-Domain Evaluation]\n",
      "  art_painting: 99.61%\n",
      "       cartoon: 99.70%\n",
      "         photo: 99.34%\n",
      "        sketch: 97.91%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loaders = []\n",
    "test_loaders  = []\n",
    "for domain in Config.DOMAINS:\n",
    "    ds_train = PACSDataset(Config.DATA_ROOT, domain, Config.TRANSFORM)\n",
    "    ds_test  = PACSDataset(Config.DATA_ROOT, domain, Config.TRANSFORM)\n",
    "    train_loaders.append(DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True))\n",
    "    test_loaders .append(DataLoader(ds_test,  batch_size=Config.BATCH_SIZE, shuffle=False))\n",
    "\n",
    "\n",
    "full_train_ds = ConcatDataset([dl.dataset for dl in train_loaders])\n",
    "full_test_ds  = ConcatDataset([dl.dataset  for dl in test_loaders ])\n",
    "full_train_loader = DataLoader(full_train_ds, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "full_test_loader  = DataLoader(full_test_ds,  batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model     = setup_baseline_model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, Config.NUM_EPOCHS + 1):\n",
    "    loss, acc = train_epoch(model, full_train_loader, criterion, optimizer)\n",
    "    print(f\"[Epoch {epoch}/{Config.NUM_EPOCHS}] Train Loss: {loss:.4f}, Train Acc: {acc:.2f}%\")\n",
    "\n",
    "test_acc = evaluate(model, full_test_loader)\n",
    "print(f\"Baseline (all domains) Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n[Per-Domain Evaluation]\")\n",
    "domain_accuracies = OrderedDict()\n",
    "for domain, loader in zip(Config.DOMAINS, test_loaders):\n",
    "    acc = evaluate(model, loader)\n",
    "    domain_accuracies[domain] = acc\n",
    "    print(f\"  {domain:>12}: {acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
