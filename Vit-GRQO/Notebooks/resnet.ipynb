{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505fe958",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from dataset import PACSDataset\n",
    "from vit_grqo import ViTGRQO, grqo_loss_from_gradients\n",
    "from encoder_decoder_vit import VisualDecoder, MultiheadAttn, DecoderAttn\n",
    "from Visual_query_heads import QueryLosses, GRQO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5524d",
   "metadata": {},
   "source": [
    "### CONFIG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "\n",
    "# Your constants\n",
    "DATA_ROOT = \"../../../pacs_data/pacs_data\"\n",
    "DOMAINS = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]\n",
    "CLASSES = [\"dog\", \"elephant\", \"giraffe\", \"guitar\", \"horse\", \"house\", \"person\"]\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 7\n",
    "NUM_EPOCHS = 5\n",
    "LR = 1e-4\n",
    "TOPK = 24\n",
    "ALPHA = 2.0\n",
    "BETA = 0.5\n",
    "TAU = 1e-3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# dataset = load_dataset(\"flwrlabs/pacs\", split=\"train\")\n",
    "\n",
    "# os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "# for domain in DOMAINS:\n",
    "#     for cls in CLASSES:\n",
    "#         os.makedirs(f\"{DATA_ROOT}/{domain}/{cls}\", exist_ok=True)\n",
    "\n",
    "# for i, example in enumerate(dataset):\n",
    "#     domain = example[\"domain\"]  \n",
    "#     label_idx = example[\"label\"]  \n",
    "#     label = CLASSES[label_idx]\n",
    "\n",
    "#     if domain not in DOMAINS:\n",
    "#         raise ValueError(f\"Unexpected domain: {domain}. Expected one of {DOMAINS}\")\n",
    "#     if label not in CLASSES:\n",
    "#         raise ValueError(f\"Unexpected label: {label}. Expected one of {CLASSES}\")\n",
    "    \n",
    "#     image = example[\"image\"]\n",
    "#     image.save(f\"{DATA_ROOT}/{domain}/{label}/image_{i}.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbdea6a",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "pacs_data = PACSDataset(DATA_ROOT, DOMAINS, TRANSFORM, BATCH_SIZE)\n",
    "ALL_DOMAINS = ['photo', 'art_painting', 'cartoon', 'sketch']\n",
    "LEAVE_OUT = 'sketch'  \n",
    "TRAIN_DOMAINS = [d for d in ALL_DOMAINS if d != LEAVE_OUT]\n",
    "VAL_DOMAIN = LEAVE_OUT\n",
    "\n",
    "train_datasets = [pacs_data.get_dataloader(domain=d, train=True) for d in TRAIN_DOMAINS]\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.ConcatDataset([d.dataset for d in train_datasets]),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation loader\n",
    "val_loader = pacs_data.get_dataloader(domain=VAL_DOMAIN, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893d9ae",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9106871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTModel, AutoFeatureExtractor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#  resnet18 Backbone ---\n",
    "dummy = torch.randn(1,3,224,224)\n",
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "backbone = torch.nn.Sequential(*list(model.children())[:-2])\n",
    "with torch.no_grad():\n",
    "    dummy_out = backbone(dummy)\n",
    "_,HIDDEN_DIM,_,_ = dummy_out.shape\n",
    "\n",
    "\n",
    "\n",
    "# GRQO Hyperparameters ---\n",
    "NUM_HEADS = 6\n",
    "DROPOUT = 0.1\n",
    "NUM_LAYERS = 3\n",
    "DDROPOUT = 0.1\n",
    "NUM_TOKENS = 32\n",
    "TEMPERATURE = 0.1\n",
    "ALPHA = 2.0\n",
    "BETA = 0.5\n",
    "TAU = 1e-3\n",
    "LAMBDA_GRQO = 1.0\n",
    "TEACHER_EMA = 0.99\n",
    "NUM_CLASSES = 7\n",
    "DECODER_DIM = 192\n",
    "\n",
    "# GRQO Decoder ---\n",
    "grqo_model = GRQO(\n",
    "    Hidden_dim=DECODER_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT,\n",
    "    num_tokens=NUM_TOKENS,\n",
    "    ddropout=DDROPOUT,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    temperature=TEMPERATURE,\n",
    "    alpha=ALPHA,\n",
    "    beta=BETA,\n",
    "    tau=TAU,\n",
    "    lambda_grqo=LAMBDA_GRQO,\n",
    "    teacher_ema=TEACHER_EMA,\n",
    "    reward_proxy=\"taylor\"\n",
    ")\n",
    "\n",
    "# Full Model ---\n",
    "class resnetGRQO(nn.Module):\n",
    "    def __init__(self, backbone, grqo_model, HD):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.grqo = grqo_model\n",
    "        self.projection_head = nn.Linear(HD,192)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        outputs = self.backbone(x)\n",
    "        B,D,H,W = outputs.shape\n",
    "        outputs = outputs.flatten(2).transpose(1,2)\n",
    "        tokens = self.projection_head(outputs)\n",
    "        return self.grqo(tokens, labels)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Optimizer ---\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.AdamW(trainable_params, lr=LR, weight_decay=0.01)\n",
    "\n",
    "print(f\"Model initialized on {device}\")\n",
    "print(f\"Hidden dim: {HIDDEN_DIM}, Num tokens: {NUM_TOKENS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7e896",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da2f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_cls_loss = 0.0\n",
    "    total_grqo_loss = 0.0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(images, labels)\n",
    "        \n",
    "        # Extract losses\n",
    "        loss = output['loss']\n",
    "        cls_loss = output['cls_loss']\n",
    "        grqo_loss = output['grqo_loss']\n",
    "        preds = output['preds']\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        total_cls_loss += cls_loss.item() * images.size(0)\n",
    "        total_grqo_loss += grqo_loss.item() * images.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Batch {batch_idx}, Loss: {loss.item():.4f}, '\n",
    "                  f'Cls: {cls_loss.item():.4f}, GRQO: {grqo_loss.item():.4f}')\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_cls_loss = total_cls_loss / total_samples\n",
    "    avg_grqo_loss = total_grqo_loss / total_samples\n",
    "    accuracy = correct / total_samples\n",
    "    \n",
    "    return avg_loss, avg_cls_loss, avg_grqo_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9dbc43",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c48930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # GRQO needs gradients even during validation\n",
    "        with torch.set_grad_enabled(True):\n",
    "            output = model(images, labels)\n",
    "            preds = output['preds']\n",
    "        \n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3fb6ed",
   "metadata": {},
   "source": [
    "### finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a010c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DOMAINS = ['sketch', 'photo', 'art_painting', 'cartoon']\n",
    "lodo_results = {}\n",
    "\n",
    "for LEAVE_OUT in ALL_DOMAINS:\n",
    "    print(f\"\\n=== LODO: Leaving out domain '{LEAVE_OUT}' ===\")\n",
    "    TRAIN_DOMAINS = [d for d in ALL_DOMAINS if d != LEAVE_OUT]\n",
    "    VAL_DOMAIN = LEAVE_OUT\n",
    "\n",
    "    # Create data loaders\n",
    "    train_datasets = [pacs_data.get_dataloader(domain=d, train=True) for d in TRAIN_DOMAINS]\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.ConcatDataset([d.dataset for d in train_datasets]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_loader = pacs_data.get_dataloader(domain=VAL_DOMAIN, train=False)\n",
    "    model = resnetGRQO(backbone, grqo_model, HIDDEN_DIM).to(device)\n",
    "    FREEZE = False\n",
    "    if FREEZE:\n",
    "        for param in model.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"backbone frozen\")\n",
    "    else:\n",
    "        print(\"backbone trainable\")\n",
    "\n",
    "    # Ensure GRQO is trainable\n",
    "    for param in model.grqo.parameters():\n",
    "        param.requires_grad = True\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_cls, train_grqo, train_acc = train_epoch(model, train_loader, optimizer, DEVICE)\n",
    "        \n",
    "        # Validate  \n",
    "        val_acc = validate(model, val_loader, DEVICE)\n",
    "        \n",
    "        print(f\"Train - Loss: {train_loss:.4f}, Cls: {train_cls:.4f}, \"\n",
    "              f\"GRQO: {train_grqo:.4f}, Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Acc ({VAL_DOMAIN}): {val_acc:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "    \n",
    "    lodo_results[VAL_DOMAIN] = best_val_acc\n",
    "    print(f\"Best Val Acc for {VAL_DOMAIN}: {best_val_acc:.4f}\")\n",
    "\n",
    "# Cell 8: Results Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LODO RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for domain, acc in lodo_results.items():\n",
    "    print(f\"{domain:15}: {acc:.4f}\")\n",
    "\n",
    "avg_lodo = sum(lodo_results.values()) / len(lodo_results)\n",
    "print(f\"{'Average':15}: {avg_lodo:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DOMAINS = ['sketch', 'photo', 'art_painting', 'cartoon']\n",
    "lodo_results = {}\n",
    "\n",
    "for LEAVE_OUT in ALL_DOMAINS:\n",
    "    print(f\"\\n=== LODO: Leaving out domain '{LEAVE_OUT}' ===\")\n",
    "    TRAIN_DOMAINS = [d for d in ALL_DOMAINS if d != LEAVE_OUT]\n",
    "    VAL_DOMAIN = LEAVE_OUT\n",
    "\n",
    "    # Create data loaders\n",
    "    train_datasets = [pacs_data.get_dataloader(domain=d, train=True) for d in TRAIN_DOMAINS]\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.ConcatDataset([d.dataset for d in train_datasets]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_loader = pacs_data.get_dataloader(domain=VAL_DOMAIN, train=False)\n",
    "\n",
    "    # Reset model for this split\n",
    "    model = resnetGRQO(backbone, grqo_model, HIDDEN_DIM).to(device)\n",
    "    FREEZE = True\n",
    "    if FREEZE:\n",
    "        for param in model.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"backbone frozen\")\n",
    "    else:\n",
    "        print(\"backbone trainable\")\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), \n",
    "        lr=LR, weight_decay=0.01\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_cls, train_grqo, train_acc = train_epoch(model, train_loader, optimizer, DEVICE)\n",
    "        \n",
    "        # Validate  \n",
    "        val_acc = validate(model, val_loader, DEVICE)\n",
    "        \n",
    "        print(f\"Train - Loss: {train_loss:.4f}, Cls: {train_cls:.4f}, \"\n",
    "              f\"GRQO: {train_grqo:.4f}, Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Acc ({VAL_DOMAIN}): {val_acc:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "    \n",
    "    lodo_results[VAL_DOMAIN] = best_val_acc\n",
    "    print(f\"Best Val Acc for {VAL_DOMAIN}: {best_val_acc:.4f}\")\n",
    "\n",
    "# Cell 8: Results Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LODO RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for domain, acc in lodo_results.items():\n",
    "    print(f\"{domain:15}: {acc:.4f}\")\n",
    "\n",
    "avg_lodo = sum(lodo_results.values()) / len(lodo_results)\n",
    "print(f\"{'Average':15}: {avg_lodo:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1676ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Baseline: Train & Validate on All Domains ===\")\n",
    "\n",
    "ALL_DOMAINS = ['sketch', 'photo', 'art_painting', 'cartoon']\n",
    "# Train loader with all domains\n",
    "all_train_datasets = [pacs_data.get_dataloader(domain=d, train=True) for d in ALL_DOMAINS]\n",
    "train_loader_all = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.ConcatDataset([d.dataset for d in all_train_datasets]),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation loaders (per domain and all combined)\n",
    "val_loaders_per_domain = {d: pacs_data.get_dataloader(domain=d, train=False) for d in ALL_DOMAINS}\n",
    "all_val_datasets = [pacs_data.get_dataloader(domain=d, train=False) for d in ALL_DOMAINS]\n",
    "val_loader_all = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.ConcatDataset([d.dataset for d in all_val_datasets]),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Model (no freezing)\n",
    "baseline_model = torchvision.models.resnet18(weights='IMAGENET1K_V1').to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(baseline_model.parameters(), lr=LR, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_val_per_domain = {}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    # ---- Train ----\n",
    "    baseline_model.train()\n",
    "    running_loss, running_corrects, running_samples = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in train_loader_all:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        outputs = baseline_model(images)\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        running_samples += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / running_samples\n",
    "    train_acc = running_corrects / running_samples\n",
    "\n",
    "    # ---- Validation (all domains combined) ----\n",
    "    baseline_model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader_all:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = baseline_model(images)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    # ---- Validation (per domain) ----\n",
    "    per_domain_accs = {}\n",
    "    baseline_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for domain, loader in val_loaders_per_domain.items():\n",
    "            correct, total = 0, 0\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = baseline_model(images)\n",
    "                preds = outputs.logits.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "            per_domain_accs[domain] = correct / total if total > 0 else 0.0\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Acc (All Domains Combined): {val_acc:.4f}\")\n",
    "    for domain, acc in per_domain_accs.items():\n",
    "        print(f\"  {domain:15}: {acc:.4f}\")\n",
    "\n",
    "    # Track best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_val_per_domain = per_domain_accs.copy()\n",
    "\n",
    "# ---------------- Results Summary ----------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LODO RESULTS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for domain, acc in lodo_results.items():\n",
    "    print(f\"{domain:15}: {acc:.4f}\")\n",
    "\n",
    "avg_lodo = sum(lodo_results.values()) / len(lodo_results)\n",
    "print(f\"{'Average LODO':15}: {avg_lodo:.4f}\")\n",
    "print(f\"{'All-domains baseline':15}: {best_val_acc:.4f}\")\n",
    "for domain, acc in best_val_per_domain.items():\n",
    "    print(f\"  {domain:15}: {acc:.4f}\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a55da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "results = {\n",
    "    \"photo\": 0.9581,\n",
    "    \"art_painting\": 0.7293,\n",
    "    \"cartoon\": 0.7186,\n",
    "    \"sketch\": 0.3461,\n",
    "    \"All-domains baseline\": 0.9010\n",
    "}\n",
    "\n",
    "# Prepare labels & values; wrap long label onto two lines for neatness\n",
    "labels = []\n",
    "values = []\n",
    "for k, v in results.items():\n",
    "    if \"All-domains\" in k:\n",
    "        labels.append(\"All-domains\\nbaseline\")   # wrap long label\n",
    "    else:\n",
    "        labels.append(k.replace(\"_\", \" \"))       # nicer display for underscores\n",
    "    values.append(v)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "x = range(len(labels))\n",
    "\n",
    "# Draw bars; make baseline visually distinct\n",
    "colors = [\"#4C72B0\", \"#55A868\", \"#C44E52\", \"#8172B2\", \"#888888\"]\n",
    "bars = ax.bar(x, values, color=colors, edgecolor=\"black\", linewidth=0.7)\n",
    "\n",
    "# Axis and ticks\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize=11)\n",
    "ax.set_title(\"LODO Results by Domain\", fontsize=13, weight=\"bold\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, fontsize=10, rotation=0, ha=\"center\")\n",
    "\n",
    "# Add horizontal grid lines for readability (below bars)\n",
    "ax.yaxis.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Annotate values above bars with consistent alignment\n",
    "for bar, val in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + 0.02,\n",
    "        f\"{val:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "        fontweight=\"semibold\"\n",
    "    )\n",
    "\n",
    "# Tidy up spines\n",
    "for spine in (\"top\", \"right\"):\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save optionally:\n",
    "# fig.savefig(\"lodo_results_bar.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
